import streamlit as st
import pandas as pd
import numpy as np
import requests
from bs4 import BeautifulSoup
from tqdm import tqdm
import time
import re
import os
import datetime as dt

# ãƒšãƒ¼ã‚¸è¨­å®š
st.set_page_config(
    page_title="å•†å“ãƒ‡ãƒ¼ã‚¿å–å¾—ãƒ„ãƒ¼ãƒ«",
    page_icon="ğŸ“Š",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ–
if 'df_onlinestore' not in st.session_state:
    st.session_state.df_onlinestore = None
if 'df_rakuten' not in st.session_state:
    st.session_state.df_rakuten = None
if 'sale_list' not in st.session_state:
    st.session_state.sale_list = None

# ã‚¿ã‚¤ãƒˆãƒ«
st.title("ğŸ“Š å•†å“ãƒ‡ãƒ¼ã‚¿å–å¾—ãƒ„ãƒ¼ãƒ«")
st.markdown("---")

# CSVãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿æ©Ÿèƒ½
def load_csv_data_from_upload(uploaded_file):
    """ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸCSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€é–¢æ•°"""
    try:
        # ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿
        sale_list = pd.read_csv(uploaded_file)
        st.session_state.sale_list = sale_list
        st.success(f"CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ: {uploaded_file.name}")
        return sale_list
    except Exception as e:
        st.error(f"CSVãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
        return None


# è‡ªç¤¾ã‚µã‚¤ãƒˆã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°é–¢æ•°
def scrape_own_site(sale_list):
    """è‡ªç¤¾ã‚µã‚¤ãƒˆã®å•†å“æƒ…å ±ã‚’ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ã™ã‚‹é–¢æ•°"""
    st.info("è‡ªç¤¾ã‚µã‚¤ãƒˆã®ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ã‚’é–‹å§‹ã—ã¾ã™...")
    
    # å•†å“æƒ…å ±ã‚’æ ¼ç´ã™ã‚‹ãƒªã‚¹ãƒˆ
    onlinestore_data = []
    
    # ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼
    progress_bar = st.progress(0)
    status_text = st.empty()
    
    total_items = len(sale_list['å•†å“ã‚³ãƒ¼ãƒ‰'])
    
    for idx, code in enumerate(sale_list['å•†å“ã‚³ãƒ¼ãƒ‰']):
        try:
            # é€²æ—æ›´æ–°
            progress = (idx + 1) / total_items
            progress_bar.progress(progress)
            status_text.text(f"å‡¦ç†ä¸­: {idx + 1}/{total_items} - å•†å“ã‚³ãƒ¼ãƒ‰: {code}")
            
            url = f'https://www.tonya.co.jp/shop/g/g{code}'
            res = requests.get(url)
            soup = BeautifulSoup(res.text, 'html.parser')

            # å„é …ç›®ã®åˆæœŸåŒ–
            item_dict = {
                'No': None,
                'Name': None,
                'Price': None,
                'Point': None,
                'Stock': None,
                'Icon': []
            }

            # å•†å“è©³ç´°ãƒ–ãƒ­ãƒƒã‚¯å–å¾—
            detail_div = soup.find('div', class_='goodsproductdetail_')
            if detail_div is None:
                continue

            # å•†å“ã‚³ãƒ¼ãƒ‰
            code_span = detail_div.find('span', class_='goodscode_id_number_')
            if code_span:
                item_dict['No'] = int(re.sub('å•†å“ã‚³ãƒ¼ãƒ‰ï¼š', '', code_span.text))

            # å•†å“å
            name_h2 = detail_div.find('h2', class_='goods_rifhtname_')
            if name_h2:
                item_dict['Name'] = name_h2.text

            # ä¾¡æ ¼
            price_span = detail_div.find('span', class_='goods_detail_saleprice_')
            if price_span:
                price_text = price_span.text.replace('å††ï¼ˆç¨è¾¼ï¼‰', '')
            else:
                price_h2 = detail_div.find('h2', class_='goods_price_')
                price_text = price_h2.text.replace('å††ï¼ˆç¨è¾¼ï¼‰', '') if price_h2 else None
            if price_text:
                # é‡‘é¡ã¯ã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šã®æ–‡å­—åˆ—ã¨ã—ã¦æ ¼ç´
                price_int = int(price_text.replace(',', ''))
                item_dict['Price'] = f"{price_int:,}"

            # ã‚¢ã‚¤ã‚³ãƒ³
            icon_div = detail_div.find('div', class_='icon_')
            if icon_div:
                for img in icon_div.find_all('img'):
                    src = img.get('src', '')
                    if src == '/img/sys/new.gif':
                        item_dict['Icon'].append('NEW')
                    elif src == '/img/sys/onsales.gif':
                        item_dict['Icon'].append('SALE')
                    elif src == '/img/icon/10000001.png':
                        item_dict['Icon'].append('é€æ–™ç„¡æ–™')
                    elif src == '/img/icon/10000002.png':
                        item_dict['Icon'].append('ã‚ˆã‚Šã©ã‚Šå¯¾è±¡')
                    elif src == '/img/icon/10000003.png':
                        item_dict['Icon'].append('æœŸé–“é™å®š')
                    elif src == '/img/icon/10000004.png':
                        item_dict['Icon'].append('ã‚¯ãƒ¼ãƒãƒ³é€²å‘ˆ')
                    elif src == '/img/icon/10000005.png':
                        item_dict['Icon'].append('ä¼šå“¡é™å®š')
                    elif src == '/img/icon/10000006.png':
                        item_dict['Icon'].append('ã‚ªãƒ³ãƒ©ã‚¤ãƒ³é™å®š')
                    elif src == '/img/icon/10000007.png':
                        item_dict['Icon'].append('NEW')

            # ãƒã‚¤ãƒ³ãƒˆ
            point_ul = soup.find('ul', id='point_stock')
            if point_ul:
                li_list = point_ul.find_all('li')
                if li_list:
                    point_text = li_list[0].text.replace('ãƒã‚¤ãƒ³ãƒˆï¼š', '').replace('pt', '')
                    try:
                        item_dict['Point'] = int(point_text)
                    except:
                        item_dict['Point'] = None

            # åœ¨åº«
            stock_tr = soup.find('tr', class_='id_stock_msg_')
            if stock_tr:
                stock_td = stock_tr.find('td', class_='id_txt')
                if stock_td:
                    item_dict['Stock'] = stock_td.text

            # è¾æ›¸ã‚’ãƒªã‚¹ãƒˆã«è¿½åŠ 
            onlinestore_data.append(item_dict)

        except Exception as e:
            # ã‚¨ãƒ©ãƒ¼æ™‚ã¯ã‚¹ã‚­ãƒƒãƒ—
            continue

    # ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ åŒ–
    df_onlinestore = pd.DataFrame(onlinestore_data)
    
    # salelistã®ã€Œå•†å“ã‚³ãƒ¼ãƒ‰ã€ã¨ã€Œé€šè²©å˜ä¾¡ã€ã‚’df_onlinestoreã«Noã§ç´ã¥ã‘ã¦è¿½åŠ ã—ã€å·®é¡åˆ—ã‚‚è¿½åŠ 
    salelist_renamed = sale_list.rename(columns={'å•†å“ã‚³ãƒ¼ãƒ‰': 'No', 'é€šè²©å˜ä¾¡': 'é€šè²©å˜ä¾¡'})
    df_onlinestore['No'] = df_onlinestore['No'].astype(str)
    salelist_renamed['No'] = salelist_renamed['No'].astype(str)

    # é€šè²©å˜ä¾¡ã‚’è¿½åŠ 
    df_onlinestore = pd.merge(df_onlinestore, salelist_renamed[['No', 'é€šè²©å˜ä¾¡']], on='No', how='left')

    # é€šè²©å˜ä¾¡ã‚‚ã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šã®æ–‡å­—åˆ—ã«å¤‰æ›
    df_onlinestore['é€šè²©å˜ä¾¡'] = df_onlinestore['é€šè²©å˜ä¾¡'].apply(
        lambda x: f"{int(str(x).replace(',', '')):,}" if pd.notnull(x) and str(x).replace(',', '').isdigit() else x
    )

    # å·®é¡åˆ—ã‚’è¿½åŠ ï¼ˆPrice - é€šè²©å˜ä¾¡ï¼‰
    def calc_diff(row):
        try:
            price = int(str(row['Price']).replace(',', ''))
            sale = int(str(row['é€šè²©å˜ä¾¡']).replace(',', ''))
            return f"{price - sale:,}"
        except:
            return None

    df_onlinestore['å·®é¡'] = df_onlinestore.apply(calc_diff, axis=1)
    
    # ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼ã‚’å®Œäº†
    progress_bar.progress(1.0)
    status_text.text("ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°å®Œäº†ï¼")
    
    return df_onlinestore

# æ¥½å¤©å¸‚å ´APIå–å¾—é–¢æ•°
def get_rakuten_data(sale_list):
    """æ¥½å¤©å¸‚å ´APIã‹ã‚‰å•†å“æƒ…å ±ã‚’å–å¾—ã™ã‚‹é–¢æ•°"""
    st.info("æ¥½å¤©å¸‚å ´APIã‹ã‚‰ã®ãƒ‡ãƒ¼ã‚¿å–å¾—ã‚’é–‹å§‹ã—ã¾ã™...")
    
    REQUEST_URL = "https://app.rakuten.co.jp/services/api/IchibaItem/Search/20170706"
    APP_ID = 1027604414937000350

    # å•†å“ã‚³ãƒ¼ãƒ‰æ‹¡å¼µ
    cat1 = sale_list[sale_list['å¤§åˆ†é¡ã‚³ãƒ¼ãƒ‰'] == 1]
    cat2 = sale_list[sale_list['å¤§åˆ†é¡ã‚³ãƒ¼ãƒ‰'] == 2]
    other = sale_list[~sale_list['å¤§åˆ†é¡ã‚³ãƒ¼ãƒ‰'].isin([1, 2])]

    rows = []
    for _, row in cat1.iterrows():
        code = str(row['å•†å“ã‚³ãƒ¼ãƒ‰'])
        for i, suf in enumerate(['-100', '-200', '-300', '-400', '-500'], 1):
            r = row.copy()
            r['å•†å“ã‚³ãƒ¼ãƒ‰'] = code + suf
            r['é€šè²©å˜ä¾¡'] = float(str(row['é€šè²©å˜ä¾¡']).replace(',', '')) * i if row['é€šè²©å˜ä¾¡'] else np.nan
            rows.append(r)
    for _, row in cat2.iterrows():
        code = str(row['å•†å“ã‚³ãƒ¼ãƒ‰'])
        r = row.copy()
        r['å•†å“ã‚³ãƒ¼ãƒ‰'] = code + '-50'
        r['é€šè²©å˜ä¾¡'] = float(str(row['é€šè²©å˜ä¾¡']).replace(',', '')) if row['é€šè²©å˜ä¾¡'] else np.nan
        rows.append(r)
    for _, row in other.iterrows():
        r = row.copy()
        r['å•†å“ã‚³ãƒ¼ãƒ‰'] = str(row['å•†å“ã‚³ãƒ¼ãƒ‰'])
        r['é€šè²©å˜ä¾¡'] = float(str(row['é€šè²©å˜ä¾¡']).replace(',', '')) if row['é€šè²©å˜ä¾¡'] else np.nan
        rows.append(r)
    sale_list_mod = pd.DataFrame(rows)

    codes = sale_list_mod['å•†å“ã‚³ãƒ¼ãƒ‰'].astype(str).unique()
    item_list = []
    
    # ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼
    progress_bar = st.progress(0)
    status_text = st.empty()
    
    total_codes = len(codes)
    
    for idx, code in enumerate(codes):
        # é€²æ—æ›´æ–°
        progress = (idx + 1) / total_codes
        progress_bar.progress(progress)
        status_text.text(f"å‡¦ç†ä¸­: {idx + 1}/{total_codes} - å•†å“ã‚³ãƒ¼ãƒ‰: {code}")
        
        params = {
            "format": "json",
            "shopCode": "tonya",
            "keyword": code,
            "orFlag": 0,
            "hasReviewFlag": 0,
            "applicationId": APP_ID,
            "availability": 1,
            "hits": 30,
            "page": 1,
            'sort': '+itemPrice',
        }
        try:
            res = requests.get(REQUEST_URL, params=params)
            result = res.json()
        except:
            time.sleep(1.2)
            continue
        for item in result.get('Items', []):
            d = item['Item']
            url = d.get('itemUrl', '')
            url = url.replace("https://item.rakuten.co.jp/tonya/", "").replace("/?rafcid=wsc_i_is_1027604414937000350", "")
            if url == code:
                tmp = {
                    'itemCode': url,
                    'itemName': d.get('itemName', ''),
                    'itemPrice': d.get('itemPrice', ''),
                    'pointRate': d.get('pointRate', ''),
                    'postageFlag': "é€æ–™è¾¼" if d.get('postageFlag') == 0 else "é€æ–™åˆ¥" if d.get('postageFlag') == 1 else ""
                }
                item_list.append(tmp)
        time.sleep(1.2)

    df_rakuten = pd.DataFrame(item_list)
    if df_rakuten.empty:
        df_rakuten = pd.DataFrame(columns=['itemCode', 'itemName', 'itemPrice', 'pointRate', 'postageFlag'])

    df_sales = sale_list_mod[['å•†å“ã‚³ãƒ¼ãƒ‰', 'é€šè²©å˜ä¾¡', 'é€æ–™åŒºåˆ†å']].rename(columns={'å•†å“ã‚³ãƒ¼ãƒ‰': 'itemCode'})
    df_merged = pd.merge(df_rakuten, df_sales, on='itemCode', how='left')

    df_merged['itemPrice'] = df_merged['itemPrice'].replace(',', '', regex=True).astype(float)
    df_merged['é€šè²©å˜ä¾¡'] = df_merged['é€šè²©å˜ä¾¡'].astype(float)
    df_merged['å·®é¡'] = df_merged['itemPrice'] - df_merged['é€šè²©å˜ä¾¡']

    df_merged['é€šè²©å˜ä¾¡'] = df_merged['é€šè²©å˜ä¾¡'].apply(lambda x: '{:,.0f}'.format(x) if not np.isnan(x) else '')
    df_merged['itemPrice'] = df_merged['itemPrice'].apply(lambda x: '{:,.0f}'.format(x) if not np.isnan(x) else '')
    df_merged['å·®é¡'] = df_merged['å·®é¡'].apply(lambda x: '{:,.0f}'.format(x) if not np.isnan(x) else '')

    cols = ['itemCode', 'itemName', 'itemPrice', 'pointRate', 'postageFlag', 'é€šè²©å˜ä¾¡', 'å·®é¡', 'é€æ–™åŒºåˆ†å']
    df_merged = df_merged[cols]
    
    # ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼ã‚’å®Œäº†
    progress_bar.progress(1.0)
    status_text.text("æ¥½å¤©å¸‚å ´APIå–å¾—å®Œäº†ï¼")
    
    return df_merged

# ã‚µã‚¤ãƒ‰ãƒãƒ¼
def render_sidebar():
    """ã‚µã‚¤ãƒ‰ãƒãƒ¼ã®è¡¨ç¤º"""
    # ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§ãƒ‡ãƒ¼ã‚¿å–å¾—æ–¹æ³•ã®é¸æŠ
    if st.session_state.sale_list is not None:
        st.sidebar.markdown("---")
        st.sidebar.subheader("ğŸ”§ ãƒ‡ãƒ¼ã‚¿å–å¾—æ–¹æ³•")
        
        data_source = st.sidebar.radio(
            "å–å¾—ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ã‚’é¸æŠï¼š",
            ["è‡ªç¤¾ã‚µã‚¤ãƒˆã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°", "æ¥½å¤©å¸‚å ´APIå–å¾—"],
            index=0
        )
        
        st.sidebar.markdown("---")
        
        # é¸æŠã«å¿œã˜ãŸãƒ‡ãƒ¼ã‚¿å–å¾—ãƒœã‚¿ãƒ³
        if data_source == "è‡ªç¤¾ã‚µã‚¤ãƒˆã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°":
            st.sidebar.subheader("ğŸª è‡ªç¤¾ã‚µã‚¤ãƒˆã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°")
            st.sidebar.markdown("è‡ªç¤¾ã‚µã‚¤ãƒˆã‹ã‚‰å•†å“æƒ…å ±ã‚’å–å¾—ã—ã¾ã™ã€‚")
            
            if st.sidebar.button("ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°é–‹å§‹", type="primary", use_container_width=True):
                df_result = scrape_own_site(st.session_state.sale_list)
                st.session_state.df_onlinestore = df_result
                
                # ãƒ¡ã‚¤ãƒ³ã‚¨ãƒªã‚¢ã«çµæœã‚’è¡¨ç¤ºã™ã‚‹ãŸã‚ã«ãƒªãƒ€ã‚¤ãƒ¬ã‚¯ãƒˆ
                st.rerun()
        
        elif data_source == "æ¥½å¤©å¸‚å ´APIå–å¾—":
            st.sidebar.subheader("ğŸ›’ æ¥½å¤©å¸‚å ´APIå–å¾—")
            st.sidebar.markdown("æ¥½å¤©å¸‚å ´APIã‹ã‚‰å•†å“æƒ…å ±ã‚’å–å¾—ã—ã¾ã™ã€‚")
            
            if st.sidebar.button("APIå–å¾—é–‹å§‹", type="primary", use_container_width=True):
                df_result = get_rakuten_data(st.session_state.sale_list)
                st.session_state.df_rakuten = df_result
                
                # ãƒ¡ã‚¤ãƒ³ã‚¨ãƒªã‚¢ã«çµæœã‚’è¡¨ç¤ºã™ã‚‹ãŸã‚ã«ãƒªãƒ€ã‚¤ãƒ¬ã‚¯ãƒˆ
                st.rerun()

# ãƒ¡ã‚¤ãƒ³å‡¦ç†
def main():
    # CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã‚»ã‚¯ã‚·ãƒ§ãƒ³
    st.subheader("ğŸ“ CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰")
    
    uploaded_file = st.file_uploader(
        "CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠã—ã¦ãã ã•ã„",
        type=['csv'],
        help="å•†å“ãƒ‡ãƒ¼ã‚¿ãŒå«ã¾ã‚ŒãŸCSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„"
    )
    
    if uploaded_file is not None:
        # CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿
        sale_list = load_csv_data_from_upload(uploaded_file)
        
        if sale_list is not None:
            st.success(f"èª­ã¿è¾¼ã¿å®Œäº†: {len(sale_list)}ä»¶ã®å•†å“ãƒ‡ãƒ¼ã‚¿")
            st.info("ğŸ‘ˆ ã‚µã‚¤ãƒ‰ãƒãƒ¼ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿å–å¾—æ–¹æ³•ã‚’é¸æŠã—ã¦ãã ã•ã„")
    
    else:
        st.info("ğŸ‘† CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ã€è‡ªç¤¾ã‚µã‚¤ãƒˆã¾ãŸã¯æ¥½å¤©å¸‚å ´ã®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã—ã¾ã—ã‚‡ã†ï¼")
    
    # ã‚µã‚¤ãƒ‰ãƒãƒ¼ã‚’è¡¨ç¤ºï¼ˆCSVèª­ã¿è¾¼ã¿å¾Œã«å®Ÿè¡Œï¼‰
    render_sidebar()

    # çµæœè¡¨ç¤º
    if st.session_state.df_onlinestore is not None:
        st.markdown("---")
        st.subheader("ğŸ“Š è‡ªç¤¾ã‚µã‚¤ãƒˆå–å¾—çµæœ")
        st.success("ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ãŒå®Œäº†ã—ã¾ã—ãŸï¼")
        
        # é«˜ã•ã‚’æŒ‡å®šã—ã¦ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’è¡¨ç¤º
        st.dataframe(
            st.session_state.df_onlinestore,
            use_container_width=True,
            height=600
        )
        
        # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³
        csv_data = st.session_state.df_onlinestore.to_csv(index=False, encoding='utf-8-sig')
        st.download_button(
            label="è‡ªç¤¾ã‚µã‚¤ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
            data=csv_data,
            file_name=f"è‡ªç¤¾ã‚µã‚¤ãƒˆãƒ‡ãƒ¼ã‚¿_{dt.datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
            mime="text/csv"
        )
    
    if st.session_state.df_rakuten is not None:
        st.markdown("---")
        st.subheader("ğŸ“Š æ¥½å¤©å¸‚å ´å–å¾—çµæœ")
        st.success("æ¥½å¤©å¸‚å ´APIå–å¾—ãŒå®Œäº†ã—ã¾ã—ãŸï¼")
        
        # é«˜ã•ã‚’æŒ‡å®šã—ã¦ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’è¡¨ç¤º
        st.dataframe(
            st.session_state.df_rakuten,
            use_container_width=True,
            height=800
        )
        
        # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³
        csv_data = st.session_state.df_rakuten.to_csv(index=False, encoding='utf-8-sig')
        st.download_button(
            label="æ¥½å¤©å¸‚å ´ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
            data=csv_data,
            file_name=f"æ¥½å¤©å¸‚å ´ãƒ‡ãƒ¼ã‚¿_{dt.datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
            mime="text/csv"
        )

    # ã‚µã‚¤ãƒ‰ãƒãƒ¼ã«çµæœè¡¨ç¤º
    st.sidebar.markdown("---")
    st.sidebar.subheader("ğŸ“Š å–å¾—çµæœ")
    
    if st.session_state.df_onlinestore is not None:
        st.sidebar.success(f"è‡ªç¤¾ã‚µã‚¤ãƒˆãƒ‡ãƒ¼ã‚¿: {len(st.session_state.df_onlinestore)}ä»¶")
    
    if st.session_state.df_rakuten is not None:
        st.sidebar.success(f"æ¥½å¤©å¸‚å ´ãƒ‡ãƒ¼ã‚¿: {len(st.session_state.df_rakuten)}ä»¶")

    # ãƒ•ãƒƒã‚¿ãƒ¼
    st.markdown("---")
    st.markdown(
        """
        <div style='text-align: center; color: #666;'>
            <small>å•†å“ãƒ‡ãƒ¼ã‚¿å–å¾—ãƒ„ãƒ¼ãƒ« v1.0 | æ ªå¼ä¼šç¤¾ãƒ•ãƒ¬ãƒƒã‚·ãƒ¥ãƒ­ãƒ¼ã‚¹ã‚¿ãƒ¼çˆç²å•å±‹</small>
        </div>
        """,
        unsafe_allow_html=True
    )

if __name__ == "__main__":
    main()
